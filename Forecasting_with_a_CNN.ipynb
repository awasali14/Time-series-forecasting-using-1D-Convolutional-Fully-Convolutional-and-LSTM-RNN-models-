{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjvUR9md11bFkyXOmP58Oa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awasali14/Time-series-forecasting-using-1D-Convolutional-Fully-Convolutional-and-LSTM-RNN-models-/blob/main/Forecasting_with_a_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing With 1D-Convolutional Layers"
      ],
      "metadata": {
        "id": "izT8oExJkEu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wz11RC7juiK"
      },
      "outputs": [],
      "source": [
        "#Resets session, sets seeds, defines a sequential model with a 1D convolutional layer followed by LSTM layers,\n",
        "#compiles it, and begins training with a learning rate scheduler.\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = seq2seq_window_dataset(x_train, window_size,\n",
        "                                   batch_size=128)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  keras.layers.LSTM(32, return_sequences=True),\n",
        "  keras.layers.LSTM(32, return_sequences=True),\n",
        "  keras.layers.Dense(1),\n",
        "  keras.layers.Lambda(lambda x: x * 200)\n",
        "])\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plots learning rates against losses on a semilogarithmic scale to determine the optimal learning rate.\n",
        "\n",
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 30])"
      ],
      "metadata": {
        "id": "1ns1uFSZj4ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resets session, sets seeds, prepares datasets,\n",
        "#builds the same model structure as before,\n",
        "#and trains it with validation data using model checkpointing and early stopping.\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = seq2seq_window_dataset(x_train, window_size,\n",
        "                                   batch_size=128)\n",
        "valid_set = seq2seq_window_dataset(x_valid, window_size,\n",
        "                                   batch_size=128)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  keras.layers.LSTM(32, return_sequences=True),\n",
        "  keras.layers.LSTM(32, return_sequences=True),\n",
        "  keras.layers.Dense(1),\n",
        "  keras.layers.Lambda(lambda x: x * 200)\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"my_checkpoint.h5\", save_best_only=True)\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=50)\n",
        "model.fit(train_set, epochs=500,\n",
        "          validation_data=valid_set,\n",
        "          callbacks=[early_stopping, model_checkpoint])"
      ],
      "metadata": {
        "id": "btZGo7m3j4Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loads the best-performing model saved during training from a checkpoint.\n",
        "\n",
        "model = keras.models.load_model(\"my_checkpoint.h5\")"
      ],
      "metadata": {
        "id": "MSQMe-hWj4hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uses the model to forecast the series data, then adjusts the forecast to align with the split time.\n",
        "\n",
        "rnn_forecast = model_forecast(model, series[:,  np.newaxis], window_size)\n",
        "rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]"
      ],
      "metadata": {
        "id": "Ue97PE4jj4v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizes the validation set and the model's forecasts on the same plot for comparison.\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, rnn_forecast)"
      ],
      "metadata": {
        "id": "nK5UT9aoj48t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculates and displays the mean absolute error between the validation data and the modelâ€™s forecasts.\n",
        "\n",
        "keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()"
      ],
      "metadata": {
        "id": "21tExNZqj5G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fully Convolutional Forecasting"
      ],
      "metadata": {
        "id": "lbDedHitj-iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Resets session, sets seeds,\n",
        "#initializes a fully convolutional model using multiple dilated convolutional layers to process sequences,\n",
        "#and begins training with a learning rate scheduler.\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 64\n",
        "train_set = seq2seq_window_dataset(x_train, window_size,\n",
        "                                   batch_size=128)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
        "for dilation_rate in (1, 2, 4, 8, 16, 32):\n",
        "    model.add(\n",
        "      keras.layers.Conv1D(filters=32,\n",
        "                          kernel_size=2,\n",
        "                          strides=1,\n",
        "                          dilation_rate=dilation_rate,\n",
        "                          padding=\"causal\",\n",
        "                          activation=\"relu\")\n",
        "    )\n",
        "model.add(keras.layers.Conv1D(filters=1, kernel_size=1))\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-4 * 10**(epoch / 30))\n",
        "optimizer = keras.optimizers.Adam(lr=1e-4)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "metadata": {
        "id": "NV4q1lzdj5e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plots learning rates against losses on a semilogarithmic scale to analyze the optimal learning rate for the fully convolutional model.\n",
        "\n",
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-4, 1e-1, 0, 30])"
      ],
      "metadata": {
        "id": "T71sUjPyj5qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resets session, sets seeds,\n",
        "#prepares datasets, builds and compiles a fully convolutional model with multiple dilated layers,\n",
        "#and trains it using early stopping and model checkpointing with validation data\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 64\n",
        "train_set = seq2seq_window_dataset(x_train, window_size,\n",
        "                                   batch_size=128)\n",
        "valid_set = seq2seq_window_dataset(x_valid, window_size,\n",
        "                                   batch_size=128)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
        "for dilation_rate in (1, 2, 4, 8, 16, 32):\n",
        "    model.add(\n",
        "      keras.layers.Conv1D(filters=32,\n",
        "                          kernel_size=2,\n",
        "                          strides=1,\n",
        "                          dilation_rate=dilation_rate,\n",
        "                          padding=\"causal\",\n",
        "                          activation=\"relu\")\n",
        "    )\n",
        "model.add(keras.layers.Conv1D(filters=1, kernel_size=1))\n",
        "optimizer = keras.optimizers.Adam(lr=3e-4)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"my_checkpoint.h5\", save_best_only=True)\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=50)\n",
        "history = model.fit(train_set, epochs=500,\n",
        "                    validation_data=valid_set,\n",
        "                    callbacks=[early_stopping, model_checkpoint])"
      ],
      "metadata": {
        "id": "xt8bo8KEj51n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loads the model that achieved the best performance during training from a checkpoint file.\n",
        "\n",
        "model = keras.models.load_model(\"my_checkpoint.h5\")"
      ],
      "metadata": {
        "id": "jNqB88a-j6BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generates predictions for the entire series using the trained model and adjusts the output to align with the forecast period.\n",
        "\n",
        "cnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n",
        "cnn_forecast = cnn_forecast[split_time - window_size:-1, -1, 0]"
      ],
      "metadata": {
        "id": "RWYmPfJ4j6NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizes the actual validation data and the CNN model's forecasts together on a plot for comparison.\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, cnn_forecast)"
      ],
      "metadata": {
        "id": "jes4zVOij6Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#omputes and displays the mean absolute error between the CNN forecasts and the actual validation data.\n",
        "\n",
        "keras.metrics.mean_absolute_error(x_valid, cnn_forecast).numpy()"
      ],
      "metadata": {
        "id": "jyI5SiQJj6kB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}